{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0234dc",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## Laboratorio 4\n",
    "## Métodos de clasificación: RandomForest, AdaBoost y XGBoost\n",
    "\n",
    "### Grupo: \n",
    "- Sebastián Gacitúa\n",
    "- Patricia Calisto\n",
    "- Bastián Guzmán\n",
    "- Fabián Ragnarsson\n",
    "- Matthias Clein\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bd9d7",
   "metadata": {},
   "source": [
    "### Objetivo:\n",
    "En este laboratorio deberá utilizar los métodos de clasificación, RandomForest, AdaBoost y XGBoost. Para ello, utilizará la\n",
    "base de kaggle subidas a canvas en el módulo de tareas.\n",
    "En este laboratorio deberá ajustar un modelo que permita predecir si las noticias entregadas son falsas o no, por el término\n",
    "Fake News. Para ello, deberá investigar cómo tokenizar cada noticia (conteo de palabras) y determinar cuáles son las que\n",
    "más influyen para esta clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5902a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # Librería para utlizar expresiones regulares\n",
    "import nltk\n",
    "from nltk.corpus  import stopwords\n",
    "from nltk.stem.porter import PorterStemmer # Librerías para implementar stemming\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c0d1f",
   "metadata": {},
   "source": [
    "### Descargar las stopword desde la librería nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90e602c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/matthiascleinespinoza/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c773de",
   "metadata": {},
   "source": [
    "### Cargar DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c912fc6",
   "metadata": {},
   "source": [
    "Se cargan los DataFrames y se rellenan los valores nulos de *train* con un string vacío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b834e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./fake-news/train.csv\").fillna(\"\")\n",
    "test = pd.read_csv(\"./fake-news/test.csv\") \n",
    "submit = pd.read_csv(\"./fake-news/submit.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d682fb",
   "metadata": {},
   "source": [
    "Se añade una columna al DataFrame test con las etiquetas de los textos y se rellenan los valores nulos de *test* con un string vacío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242ab060",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"label\"] = submit[\"label\"]\n",
    "test = test.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdfd97f",
   "metadata": {},
   "source": [
    "Se imprimen las dimensiones de todos los DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f27e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20800, 5)\n",
      "(5200, 5)\n",
      "(5200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(submit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a0414c",
   "metadata": {},
   "source": [
    "### Información de los DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e3c6f",
   "metadata": {},
   "source": [
    "Se imprime la información de los DataFrames de *train* y *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6608723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20800 non-null  object\n",
      " 2   author  20800 non-null  object\n",
      " 3   text    20800 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9709dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5200 entries, 0 to 5199\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      5200 non-null   int64 \n",
      " 1   title   5200 non-null   object\n",
      " 2   author  5200 non-null   object\n",
      " 3   text    5200 non-null   object\n",
      " 4   label   5200 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 203.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8243c0",
   "metadata": {},
   "source": [
    "### Texto de *train* y *test*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662cffe6",
   "metadata": {},
   "source": [
    "Los textos de *train* y *test* serán la concatenación de las variables *author* y *title* de cada DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36fe7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = train[\"author\"] + \" \" + train[\"title\"]\n",
    "text_test = test[\"author\"] + \" \" + test[\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4903d2",
   "metadata": {},
   "source": [
    "### Tokenización y Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd6aeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizaremos stemming para convertir las palabras a sus raices \n",
    "#removiendo sufijos y prefijos de estas.\n",
    "port = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45e2882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    #Utilizaremos la siguiente expresión regular que substituye todo \n",
    "    #caracter que no sea una letra de la \"a - z\" y reemplaza el elemento\n",
    "    # con un espacio, eliminando símbolos especiales o números\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content) \n",
    "\n",
    "    stemmed_content = stemmed_content.lower() # Convierte todo a minúsculas \n",
    "    stemmed_content = stemmed_content.split() # Crea una lista separando cada una de las palbras\n",
    "    \n",
    "    #Aplicará stemming a toda palabra que no sea una una stopword\n",
    "    #El resultado será guardado en una lista\n",
    "    \n",
    "    stemmed_content = [port.stem(word) for word in stemmed_content if not word in stopwords.words('english')] \n",
    "    \n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e7371",
   "metadata": {},
   "source": [
    "Aplicamos la función *stemming* a los textos de *train* y *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c6bcf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = text_train.apply(stemming)\n",
    "text_test = text_test.apply(stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d7ce1f",
   "metadata": {},
   "source": [
    "### Conjuntos de *train* y *test*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f9a14",
   "metadata": {},
   "source": [
    "Se crean los conjuntos de *train* y *test* a partir de los textos y sus etiquetas.\n",
    "- X: Texto   \n",
    "- y: Etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c95345",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = text_train\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "X_test = text_test\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71737716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        darrel lucu hous dem aid even see comey letter...\n",
       "1        daniel j flynn flynn hillari clinton big woman...\n",
       "2                   consortiumnew com truth might get fire\n",
       "3        jessica purkiss civilian kill singl us airstri...\n",
       "4        howard portnoy iranian woman jail fiction unpu...\n",
       "                               ...                        \n",
       "20795    jerom hudson rapper trump poster child white s...\n",
       "20796    benjamin hoffman n f l playoff schedul matchup...\n",
       "20797    michael j de la merc rachel abram maci said re...\n",
       "20798    alex ansari nato russia hold parallel exercis ...\n",
       "20799                            david swanson keep f aliv\n",
       "Length: 20800, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f999888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "20795    0\n",
       "20796    0\n",
       "20797    0\n",
       "20798    1\n",
       "20799    1\n",
       "Name: label, Length: 20800, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392e7b9",
   "metadata": {},
   "source": [
    "### Vectorización utlizando Tfidfvectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0180aa",
   "metadata": {},
   "source": [
    "Referencias:\n",
    "- [How to Use Tfidftransformer & Tfidfvectorizer?](https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.Y0MOnnZBw2x)\n",
    "- [fake news 98% accuracy [NLTK]](https://www.kaggle.com/code/mohanvaddella/fake-news-98-accuracy-nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2fa33",
   "metadata": {},
   "source": [
    "Se instancia el TfidfVectorizer, se le entregan los datos de entrenamiento y luego se utiliza para transformar los conjuntos de *train* y *test* de texto a números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d69b6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf = True)\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train = tfidf_vectorizer.transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b11c4c9",
   "metadata": {},
   "source": [
    "### Variables más importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a90cb8",
   "metadata": {},
   "source": [
    "El método obtiene las palabras de mayor relevancia en la transformación numérica. El resultado es almacenado en un DataFrame que luego se ordena de manera descendiente, por lo que las 3 primeras filas serán las palabras de mayor importancia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc343ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chaffetz</th>\n",
       "      <td>0.367652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lucu</th>\n",
       "      <td>0.363596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>darrel</th>\n",
       "      <td>0.359894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tfidf\n",
       "chaffetz  0.367652\n",
       "lucu      0.363596\n",
       "darrel    0.359894"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_vector_tfidfvectorizer = X_train[0] \n",
    "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index = tfidf_vectorizer.get_feature_names_out(), columns = [\"tfidf\"]) \n",
    "df.sort_values(by = [\"tfidf\"], ascending = False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a6b43",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23581c",
   "metadata": {},
   "source": [
    "Se instancia y entrena el clasificador Random Forest con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bf5bf43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_classifier = RandomForestClassifier(random_state = 0)\n",
    "RF_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201b065c",
   "metadata": {},
   "source": [
    "Predicción de los resultados con el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77065d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = RF_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfa3bcb",
   "metadata": {},
   "source": [
    "Calculamos la exactitud del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d77ef0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 63.75 %\n"
     ]
    }
   ],
   "source": [
    "RF_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy =\",round(RF_accuracy*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8ddfd18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62      2339\n",
      "           1       0.69      0.62      0.65      2861\n",
      "\n",
      "    accuracy                           0.64      5200\n",
      "   macro avg       0.64      0.64      0.64      5200\n",
      "weighted avg       0.64      0.64      0.64      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_report=classification_report(y_test, y_pred)\n",
    "print(RF_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140602b0",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a40c50",
   "metadata": {},
   "source": [
    "Se instancia y entrena el clasificador AdaBoost con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54c3f61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB_classifier = AdaBoostClassifier(random_state = 0)\n",
    "AB_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fddd3a",
   "metadata": {},
   "source": [
    "Predicción de los resultados con el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62b30c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = AB_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c446b",
   "metadata": {},
   "source": [
    "Calculamos la exactitud del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb8a2683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 63.96 %\n"
     ]
    }
   ],
   "source": [
    "AB_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy =\",round(AB_accuracy*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "698163d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.62      2339\n",
      "           1       0.69      0.64      0.66      2861\n",
      "\n",
      "    accuracy                           0.64      5200\n",
      "   macro avg       0.64      0.64      0.64      5200\n",
      "weighted avg       0.64      0.64      0.64      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AB_report=classification_report(y_test, y_pred)\n",
    "print(AB_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42932605",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b5297b",
   "metadata": {},
   "source": [
    "Se instala la librería del modelo XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce1b68e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/matthiascleinespinoza/opt/anaconda3/lib/python3.9/site-packages (1.6.2)\n",
      "Requirement already satisfied: scipy in /Users/matthiascleinespinoza/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in /Users/matthiascleinespinoza/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407764f",
   "metadata": {},
   "source": [
    "Se instancia y entrena el clasificador XGBoost con el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df6512b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_classifier= xgb.XGBClassifier(random_state=0)\n",
    "XGB_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a133be",
   "metadata": {},
   "source": [
    "Predicción de los resultados con el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82d7e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = XGB_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78090fec",
   "metadata": {},
   "source": [
    "Calculamos la exactitud del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64ec31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 63.71 %\n"
     ]
    }
   ],
   "source": [
    "XGB_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy =\",round(XGB_accuracy*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "763183ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62      2339\n",
      "           1       0.69      0.63      0.66      2861\n",
      "\n",
      "    accuracy                           0.64      5200\n",
      "   macro avg       0.64      0.64      0.64      5200\n",
      "weighted avg       0.64      0.64      0.64      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "XGB_report=classification_report(y_test, y_pred)\n",
    "print(XGB_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef25125",
   "metadata": {},
   "source": [
    "### Comparación de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73e4ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy = 63.75 %\n",
      "AdaBoost Accuracy = 63.96 %\n",
      "XGBoost Accuracy = 63.71 %\n",
      "\n",
      " Random Forest Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62      2339\n",
      "           1       0.69      0.62      0.65      2861\n",
      "\n",
      "    accuracy                           0.64      5200\n",
      "   macro avg       0.64      0.64      0.64      5200\n",
      "weighted avg       0.64      0.64      0.64      5200\n",
      "\n",
      "\n",
      " AdaBoost Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.62      2339\n",
      "           1       0.69      0.64      0.66      2861\n",
      "\n",
      "    accuracy                           0.64      5200\n",
      "   macro avg       0.64      0.64      0.64      5200\n",
      "weighted avg       0.64      0.64      0.64      5200\n",
      "\n",
      "\n",
      " XGBoost Report \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62      2339\n",
      "           1       0.69      0.63      0.66      2861\n",
      "\n",
      "    accuracy                           0.64      5200\n",
      "   macro avg       0.64      0.64      0.64      5200\n",
      "weighted avg       0.64      0.64      0.64      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy =\",round(RF_accuracy*100,2),\"%\")\n",
    "print(\"AdaBoost Accuracy =\",round(AB_accuracy*100,2),\"%\")\n",
    "print(\"XGBoost Accuracy =\",round(XGB_accuracy*100,2),\"%\")\n",
    "print(\"\\n Random Forest Report \\n\")\n",
    "print(RF_report)\n",
    "print(\"\\n AdaBoost Report \\n\")\n",
    "print(AB_report)\n",
    "print(\"\\n XGBoost Report \\n\")\n",
    "print(XGB_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a40968",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2152f",
   "metadata": {},
   "source": [
    "- De los 3 modelos implementados el con mejor rendimiento (accuracy) es AdaBoost con un 63.96%. Cabe destacar que los otros dos modelos presentan resultados similares, siendo estos 63.75% para el Random Forest y 63.71% para el XGBoost.\n",
    "- En una primera etapa de este laboratorio, se trabajó solamente considerando el dataset de entrenamiento al cual se le aplicó todo el procesamiento presentado en este notebook. Al obtener los accuracy para cada modelo quedamos sorprendidos por los excelentes resultados siendo estos cercanos al 99%. Sin embargo, cuando utilizamos el dataset de entrenamiento exclusivamente para entrenar a los modelos y el dataset de test para probarlos y obtener su exactitud, los resultados fueron muy distintos, llegando aproximadamente al 64%. Esto puede deberse a que las palabras presentes en el dataset de test no son consideradas y/o no tienen la misma importancia dentro del vectorizador que fue ajustado con el dataset de entrenamiento, lo que produce que el modelo no pueda clasificar correctamente las noticias. \n",
    "- Existen distintas formas de implementar la vectorización. En este trabajo se utilizó en primera instancia el CountVectorizer pero sus resultados no fueron tan buenos como el de Tfidfvectorizer, por lo que finalmente se realizó el cambio.\n",
    "- Tfidfvectorizer también nos permitió obtener de manera sencilla las palabras más importantes para la clasificación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab442baed0c0d8002d8544244931314372b4e866e16812c16c3d4746c71db3e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
